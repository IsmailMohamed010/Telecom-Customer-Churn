{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Telcome Customer Churn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we Build a model with **80%** Accurcy to detect Cutomer Churn based on Telcome Data:  \n",
    "    \\\n",
    "***using***\n",
    "\n",
    "**Data Cleanning**: <small>drop_duplicates & Fill Null Values.</small>\n",
    "\\\n",
    "**EDA**: <small>Show Corrlelations between Futer's and Other To Know What's Futers we will use in building the model.</small>\n",
    "\\\n",
    "**Futer Engineering**: <small>Create 2 Futers to Know outlairs.</small>\n",
    "\\\n",
    "**Outlair**: <small>Face alot of outlairs and drop them to fiter data to make it more reabel</small>\n",
    "\\\n",
    "**Build Model**: <small>Using 19 Futer as input to detect Target and split data to 80% train to 20% test.</small>\n",
    "\\\n",
    "**model used**:<small> Logistic, Decision Tree, Naive Bayes using Gaussian, KNeighbors, Support Vector Machine, Ensemble methods using Boosting,Ensemble methods using Bagging.</small>\n",
    "\\\n",
    "**Evaluting to model**: <small>Using Accuracy Score, Confusion Matrix & Classification report, and ROC Curve.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show that TotalCharges is Object we will change to numericl data\n",
    "and show SeniorCitizen as integer we will change to Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('customerID',axis=1,inplace=True)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['SeniorCitizen'] = ((df['SeniorCitizen']).map({0:\"No\",1:\"Yes\"})).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null Values in TotalCharges with Mean of Column\n",
    "meanV = df['TotalCharges'].mean()\n",
    "df['TotalCharges']=df['TotalCharges'].fillna(meanV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA For Customer Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot_ratio(data, x, hue=None, ax=None, rotate_xlabel=0):\n",
    "    ax = sns.countplot(data=data, x=x, hue=hue, ax=ax)\n",
    "    # Rotate x-axis labels based on the rotate_xlabel parameter\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=rotate_xlabel)\n",
    "    ax.set_title(x + \" Distributions\")\n",
    "    \n",
    "    total = float(len(data))\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(p.get_x() + p.get_width() / 2., height + 3,\n",
    "                    '{:.2f}%'.format((height / total) * 100), \n",
    "                    fontsize=12, weight='bold', ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.suptitle(\"Customer Information Vs Churn\")\n",
    "\n",
    "# Gender Plot.\n",
    "countplot_ratio(data=df,x='gender',hue='Churn')\n",
    "plt.title('Gender Vs Churn')\n",
    "\n",
    "# SeniorCitizen Plot.\n",
    "plt.subplot(2,2,2)\n",
    "countplot_ratio(df,x='SeniorCitizen',hue='Churn')\n",
    "plt.title('SeniorCitizen Vs Churn')\n",
    "\n",
    "# Partner Plot.\n",
    "plt.subplot(2,2,3)\n",
    "countplot_ratio(df, x='Partner',hue='Churn')\n",
    "plt.title('Partner Vs Churn')\n",
    "\n",
    "# Dependent Plot.\n",
    "plt.subplot(2,2,4)\n",
    "countplot_ratio(df,x='Dependents',hue='Churn')\n",
    "plt.title('Dependents Vs Churn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Pie(data, col):\n",
    "    '''\n",
    "    Creates pie chart that automatically adjusts to the number of categories\n",
    "    '''\n",
    "    values = data[col].value_counts()\n",
    "    explode = [0.1] + [0]*(len(values)-1)\n",
    "    colors = ['#FFD700', '#FFB6C1', '#87CEEB', '#98FB98', '#DDA0DD', '#FFA07A']\n",
    "    \n",
    "    plt.pie(\n",
    "        values,\n",
    "        labels=values.index,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=colors[:len(values)],\n",
    "        explode=explode,\n",
    "        shadow=True,\n",
    "        wedgeprops={'edgecolor': 'brown', 'linewidth': 2}\n",
    "    )\n",
    "    \n",
    "    plt.title(f'{col} State', fontweight='bold')\n",
    "    plt.gca().axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.suptitle('Customer Information State')\n",
    "\n",
    "# Gender State.\n",
    "get_Pie(df,'gender')\n",
    "\n",
    "#SeniorCitizen State.\n",
    "plt.subplot(2,2,2)\n",
    "get_Pie(df,'SeniorCitizen')\n",
    "\n",
    "#Partner State.\n",
    "plt.subplot(2,2,3)\n",
    "get_Pie(df,'Partner')\n",
    "\n",
    "#Dependents State.\n",
    "plt.subplot(2,2,4)\n",
    "get_Pie(df,'Dependents')\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA For Services**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Services First:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.suptitle('Main Services Vs Churn')\n",
    "\n",
    "# PhoneService Plot\n",
    "countplot_ratio(df,x='PhoneService',hue='Churn')\n",
    "plt.title('PhoneService Vs Churn')\n",
    "\n",
    "# MultipleLines Plot\n",
    "plt.subplot(1,3,2)\n",
    "countplot_ratio(df,x='MultipleLines',hue='Churn')\n",
    "plt.title('MultipleLines Vs Churn')\n",
    "\n",
    "# InternetService Plot\n",
    "plt.subplot(1,3,3)\n",
    "countplot_ratio(df,x='InternetService',hue='Churn')\n",
    "plt.title('InternetService Vs Churn')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1,3,1)\n",
    "plt.suptitle('Main Services State')\n",
    "\n",
    "# PhoneService Plot\n",
    "get_Pie(df,'PhoneService')\n",
    "\n",
    "#MultipleLines State.\n",
    "plt.subplot(1,3,2)\n",
    "get_Pie(df,'MultipleLines')\n",
    "\n",
    "#InternetService State.\n",
    "plt.subplot(1,3,3)\n",
    "get_Pie(df,'InternetService')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondry Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,3,1)\n",
    "plt.suptitle(\"Secondry Servives Vs Churn\")\n",
    "\n",
    "# OnlineSecurity Plot\n",
    "plt.subplot(2,3,1)\n",
    "countplot_ratio(df,x='OnlineSecurity',hue='Churn')\n",
    "plt.title('OnlineSecurity Vs Churn')\n",
    "\n",
    "# OnlineBackup Plot\n",
    "plt.subplot(2,3,2)\n",
    "countplot_ratio(df,x='OnlineBackup',hue='Churn')\n",
    "plt.title('OnlineBackup Vs Churn')\n",
    "\n",
    "# DeviceProtection Plot\n",
    "plt.subplot(2,3,3)\n",
    "countplot_ratio(df,x='DeviceProtection',hue='Churn')\n",
    "plt.title('DeviceProtection Vs Churn')\n",
    "\n",
    "# TechSupport Plot\n",
    "plt.subplot(2,3,4)\n",
    "countplot_ratio(df,x='TechSupport',hue='Churn')\n",
    "plt.title('TechSupport Vs Churn')\n",
    "\n",
    "# StreamingTV Plot\n",
    "plt.subplot(2,3,5)\n",
    "countplot_ratio(df,x='StreamingTV',hue='Churn')\n",
    "plt.title('StreamingTV Vs Churn')\n",
    "\n",
    "# StreamingMovies Plot\n",
    "plt.subplot(2,3,6)\n",
    "countplot_ratio(df,x='StreamingMovies',hue='Churn')\n",
    "plt.title('StreamingMovies Vs Churn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,3,1)\n",
    "plt.suptitle(\"Secondry Servives State\")\n",
    "\n",
    "# OnlineSecurity Plot\n",
    "plt.subplot(2,3,1)\n",
    "get_Pie(df,'OnlineSecurity')\n",
    "\n",
    "# OnlineBackup Plot\n",
    "plt.subplot(2,3,2)\n",
    "get_Pie(df,'OnlineBackup')\n",
    "\n",
    "# DeviceProtection Plot\n",
    "plt.subplot(2,3,3)\n",
    "get_Pie(df,'DeviceProtection')\n",
    "\n",
    "# TechSupport Plot\n",
    "plt.subplot(2,3,4)\n",
    "get_Pie(df,'TechSupport')\n",
    "\n",
    "# StreamingTV Plot\n",
    "plt.subplot(2,3,5)\n",
    "get_Pie(df,'StreamingTV')\n",
    "\n",
    "# StreamingMovies Plot\n",
    "plt.subplot(2,3,6)\n",
    "get_Pie(df,'StreamingMovies')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA for Payment Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.suptitle('Payment Vs Churn')\n",
    "\n",
    "# Contact Plot.\n",
    "countplot_ratio(data=df,x='Contract',hue='Churn')\n",
    "plt.title('Contract Vs Churn')\n",
    "\n",
    "# PaperlessBilling Plot.\n",
    "plt.subplot(2,2,2)\n",
    "countplot_ratio(data=df,x='PaperlessBilling',hue='Churn')\n",
    "plt.title('PaperlessBilling Vs Churn')\n",
    "\n",
    "# PaymentMethod Plot.\n",
    "plt.subplot(2,2,3)\n",
    "countplot_ratio(data=df,x='PaymentMethod',hue='Churn')\n",
    "plt.title('PaymentMethod Vs Churn')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.subplot(1,3,1)\n",
    "plt.suptitle('Payment State')\n",
    "\n",
    "# Contact Plot.\n",
    "get_Pie(df,'Contract')\n",
    "\n",
    "# PaperlessBilling Plot.\n",
    "plt.subplot(1,3,2)\n",
    "get_Pie(df,'PaperlessBilling')\n",
    "\n",
    "# PaymentMethod Plot.\n",
    "plt.subplot(1,3,3)\n",
    "get_Pie(df,'PaymentMethod')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA for Charges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['Churn'] = ['Yes','No']\n",
    "df1['MonthlyCharges'] = [(df[df['Churn'] == 'Yes']['MonthlyCharges']).agg('mean'),(df[df['Churn'] == 'No']['MonthlyCharges']).agg('mean')]\n",
    "df1['TotalCharges'] = [(df[df['Churn'] == 'Yes']['TotalCharges']).agg('mean'),(df[df['Churn'] == 'No']['TotalCharges']).agg('mean')]\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('Charges Vs Churn')\n",
    "\n",
    "# MonthlyCharges Plot.\n",
    "ax = sns.barplot(data=df1,x='Churn',y='MonthlyCharges')\n",
    "plt.title('MonthlyCharges Vs Churn')\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)\n",
    "# TotalCharges Plot.\n",
    "plt.subplot(1,2,2)\n",
    "ax = sns.barplot(data=df1,x='Churn',y='TotalCharges')\n",
    "plt.title('TotalCharges Vs Churn')\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.suptitle('Distribution of Charges')\n",
    "\n",
    "#MonthlyCharges Distribution.\n",
    "sns.distplot(df['MonthlyCharges'])\n",
    "plt.title('Distribution of MonthlyCharges')\n",
    "\n",
    "#TotalCharges Distribution.\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(df['TotalCharges'])\n",
    "plt.title('Distribution of TotalCharges')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenure Distribution.\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.distplot(df['tenure'])\n",
    "plt.title('Distribution of tenure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Futer Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {'Yes': 1,'No':0}\n",
    "MultipleLines = {'No phone service': 0,'No':0,'Yes':1}\n",
    "InternetService = {'No':0,'DSL':1,'Fiber optic':1}\n",
    "OnlineSecurity = {'No internet service':0}\n",
    "OnlineSecurity.update(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Servives Used.\n",
    "df['Total_Main_Servies'] = df['InternetService'].map(InternetService).astype(np.int64) + df['MultipleLines'].map(MultipleLines).astype(np.int64) + df['PhoneService'].map(l).astype(np.int64)\n",
    "\n",
    "df['Total_Secondry_Servies'] = df['StreamingMovies'].map(OnlineSecurity).astype(np.int64) + df['StreamingTV'].map(OnlineSecurity).astype(np.int64) + df['TechSupport'].map(OnlineSecurity).astype(np.int64) + df['DeviceProtection'].map(OnlineSecurity).astype(np.int64) + df['OnlineBackup'].map(OnlineSecurity).astype(np.int64) + df['OnlineSecurity'].map(OnlineSecurity).astype(np.int64)\n",
    "\n",
    "df['Total_Secondry_Servies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Outlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='MonthlyCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 1) & \n",
    "          ((df['MonthlyCharges'] < lower_bound) | (df['MonthlyCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='MonthlyCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 1) & \n",
    "          ((df['MonthlyCharges'] < lower_bound) | (df['MonthlyCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='MonthlyCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 1) & \n",
    "          ((df['MonthlyCharges'] < lower_bound) | (df['MonthlyCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='MonthlyCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 1) & \n",
    "          ((df['MonthlyCharges'] < lower_bound) | (df['MonthlyCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='MonthlyCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 1]['MonthlyCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 1) & \n",
    "          ((df['MonthlyCharges'] < lower_bound) | (df['MonthlyCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='MonthlyCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 1]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 1]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 1) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.25)\n",
    "Q3 = df[df['Total_Main_Servies'] == 2]['TotalCharges'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df['Total_Main_Servies'] == 2) & \n",
    "          ((df['TotalCharges'] < lower_bound) | (df['TotalCharges'] > upper_bound)))]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='TotalCharges',hue='Total_Main_Servies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df,y='tenure',hue='Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to summary evaluating model.\n",
    "name = ['Logistic', 'Decision Tree', 'Naive Bayes using Gaussian', 'KNeighbors', 'Support Vector Machine',' Ensemble methods using Boosting','Ensemble methods using Bagging']\n",
    "RUC = []\n",
    "F1_Score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprossing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "for col in df.select_dtypes('O'):\n",
    "    df[col] = (encoder.fit_transform(df[col])).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Churn'],axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_s = X_train\n",
    "X_test_s = X_test\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_s[['TotalCharges','MonthlyCharges','tenure','Total_Secondry_Servies','Total_Main_Servies']] = scaler.fit_transform(X_train[['TotalCharges','MonthlyCharges','tenure','Total_Secondry_Servies','Total_Main_Servies']])\n",
    "X_test_s[['TotalCharges','MonthlyCharges','tenure','Total_Secondry_Servies','Total_Main_Servies']] = scaler.transform(X_test[['TotalCharges','MonthlyCharges','tenure','Total_Secondry_Servies','Total_Main_Servies']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Train Model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predect X_text\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Accuracy.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=3)\n",
    "# Train Model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict X_test\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Accuracy Score.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# plotting Decision Tree of Model.\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(\n",
    "    clf, \n",
    "    filled=True, \n",
    "    feature_names=df.columns, \n",
    "    class_names=['Yes', 'No'],\n",
    "    rounded=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Model using Gaussian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train Model\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # Predict X_test\n",
    "pregnb = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Accuracy Score.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNeighbors Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# set Range of neighbors.\n",
    "param_grid = {'n_neighbors': range(1, 4)}\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Apply Grid Search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=4)\n",
    "\n",
    "# Train Model\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bist neighbor in our range\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Best value for k: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "# Train Model\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict X_test\n",
    "y_pred = knn_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Accuracy Score.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with k={best_k}: {accuracy:.2f}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 10)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, accuracies, marker='o', linestyle='-', color='b', markerfacecolor='r', markersize=8)\n",
    "plt.title('Accuracy for Different Values of k')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test_s)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Train Model\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict X_test\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate using Accuracy Score.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble methods using Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clf = BaggingClassifier(estimator=logreg, n_estimators=50, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "bagging_clf = BaggingClassifier(estimator=logreg, n_estimators=50, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict X_test.\n",
    "y_pred = bagging_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Accuracy Score.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble methods using Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "# Train model\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict X_test\n",
    "y_pred_ada = ada_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Accuracy Score.\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "Accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate useing Confusion Matrix & Classification Report:\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_test, y_pred,output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "F1_Score.append(round(report['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using ROC\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table for Evaluating model\n",
    "Accuracy = [int(round(i,2)*100) for i in Accuracy]\n",
    "Evaluating_Table = pd.DataFrame({'Model':name,'Accuracy':Accuracy})\n",
    "Evaluating_Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model is Logistic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
